{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Python the Hard Way - Session 2\n",
    "Toronto Data Literacy Group\n",
    "\n",
    "Creator: Cindy Zhong\n",
    "\n",
    "Date: January 09, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading The Data\n",
    "\n",
    "The data for the file can be downloaded from the github repository. \n",
    "If you want to get the data from Twitter youself, it is created using the code from Session 1. https://github.com/cindyzhong/trt_data_lit_grp_python/tree/master/Lesson1\n",
    "\n",
    "Next, read the tab-delimited file into Python. To do this, we can use the pandas package which provides the read_csv function for easily reading and writing data files. If you haven't used pandas before, you may need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "tweet_df = pd.read_csv(\"tweet_sample.csv\", delimiter=\",\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6478, 9)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at the dimension of the dataframe\n",
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', u'handle', u'tweet_body', u'tweet_created_at',\n",
       "       u'likes', u'retweet', u'hashtags', u'user_mentions', u'place'], dtype=object)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at the columns of the dataframe\n",
    "tweet_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Ford said last week that it will expand in Michigan and U.S. instead of building a BILLION dollar plant in Mexico. Thank you Ford &amp;amp; Fiat C!</td>\n",
       "      <td>2017-01-09 14:16:34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8055.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>It's finally happening - Fiat Chrysler just announced plans to invest $1BILLION in Michigan and Ohio plants, adding 2000 jobs. This after...</td>\n",
       "      <td>2017-01-09 14:14:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8526.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>\"groveling\" when he totally changed a 16 year old story that he had written in order to make me look bad. Just more very dishonest media!</td>\n",
       "      <td>2017-01-09 11:43:26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9363.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Hillary flunky who lost big. For the 100th time, I never \"mocked\" a disabled reporter (would never do that) but simply showed him.......</td>\n",
       "      <td>2017-01-09 11:36:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11849.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Meryl Streep, one of the most over-rated actresses in Hollywood, doesn't know me but attacked last night at the Golden Globes. She is a.....</td>\n",
       "      <td>2017-01-09 11:27:50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20514.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           handle  \\\n",
       "0  0           realDonaldTrump   \n",
       "1  1           realDonaldTrump   \n",
       "2  2           realDonaldTrump   \n",
       "3  3           realDonaldTrump   \n",
       "4  4           realDonaldTrump   \n",
       "\n",
       "                                                                                                                                        tweet_body  \\\n",
       "0  Ford said last week that it will expand in Michigan and U.S. instead of building a BILLION dollar plant in Mexico. Thank you Ford &amp; Fiat C!   \n",
       "1  It's finally happening - Fiat Chrysler just announced plans to invest $1BILLION in Michigan and Ohio plants, adding 2000 jobs. This after...      \n",
       "2  \"groveling\" when he totally changed a 16 year old story that he had written in order to make me look bad. Just more very dishonest media!         \n",
       "3  Hillary flunky who lost big. For the 100th time, I never \"mocked\" a disabled reporter (would never do that) but simply showed him.......          \n",
       "4  Meryl Streep, one of the most over-rated actresses in Hollywood, doesn't know me but attacked last night at the Golden Globes. She is a.....      \n",
       "\n",
       "      tweet_created_at  likes  retweet hashtags user_mentions place  \n",
       "0  2017-01-09 14:16:34  0.0    8055.0   []       []            NaN   \n",
       "1  2017-01-09 14:14:10  0.0    8526.0   []       []            NaN   \n",
       "2  2017-01-09 11:43:26  0.0    9363.0   []       []            NaN   \n",
       "3  2017-01-09 11:36:02  0.0    11849.0  []       []            NaN   \n",
       "4  2017-01-09 11:27:50  0.0    20514.0  []       []            NaN   "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at sample data\n",
    "tweet_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Our not very bright Vice President, Joe Biden, just stated that I wanted to \"carpet bomb\" the enemy. Sorry Joe, that was Ted Cruz!</td>\n",
       "      <td>2016-07-27 12:57:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11410.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Thank you @DallasPD!  https://t.co/ORJyN4FsNI</td>\n",
       "      <td>2016-06-17 23:24:13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Dallas Police Dept]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1774</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>#CrookedHillary is not qualified!\\r\\nhttps://t.co/6qi7KTW43O</td>\n",
       "      <td>2016-07-12 16:45:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>[CrookedHillary]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>5559</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>With just 83 days until Election Day, Trump hired one of the most extreme right-wing voices to run his campaign. https://t.co/geausYW6oD</td>\n",
       "      <td>2016-08-17 18:40:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>909</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Wow, @CNN is so negative. Their panel is a joke, biased and very dumb. I'm turning to @FoxNews where we get a fair shake! Mike will do great</td>\n",
       "      <td>2016-10-05 00:12:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CNN, Fox News]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           handle  \\\n",
       "1596  1596        realDonaldTrump   \n",
       "1995  1995        realDonaldTrump   \n",
       "1774  1774        realDonaldTrump   \n",
       "5559  5559        HillaryClinton    \n",
       "909   909         realDonaldTrump   \n",
       "\n",
       "                                                                                                                                        tweet_body  \\\n",
       "1596  Our not very bright Vice President, Joe Biden, just stated that I wanted to \"carpet bomb\" the enemy. Sorry Joe, that was Ted Cruz!             \n",
       "1995  Thank you @DallasPD!  https://t.co/ORJyN4FsNI                                                                                                  \n",
       "1774  #CrookedHillary is not qualified!\\r\\nhttps://t.co/6qi7KTW43O                                                                                   \n",
       "5559  With just 83 days until Election Day, Trump hired one of the most extreme right-wing voices to run his campaign. https://t.co/geausYW6oD       \n",
       "909   Wow, @CNN is so negative. Their panel is a joke, biased and very dumb. I'm turning to @FoxNews where we get a fair shake! Mike will do great   \n",
       "\n",
       "         tweet_created_at  likes  retweet          hashtags  \\\n",
       "1596  2016-07-27 12:57:20  0.0    11410.0  []                 \n",
       "1995  2016-06-17 23:24:13  0.0    2649.0   []                 \n",
       "1774  2016-07-12 16:45:45  0.0    12559.0  [CrookedHillary]   \n",
       "5559  2016-08-17 18:40:09  0.0    5233.0   []                 \n",
       "909   2016-10-05 00:12:59  0.0    8134.0   []                 \n",
       "\n",
       "             user_mentions place  \n",
       "1596  []                    NaN   \n",
       "1995  [Dallas Police Dept]  NaN   \n",
       "1774  []                    NaN   \n",
       "5559  []                    NaN   \n",
       "909   [CNN, Fox News]       NaN   "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also look at a ramdom sample of the rows\n",
    "tweet_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'RT @MeetThePress: Watch our interview with @KellyannePolls: Russia \"did not succeed\" in attempts to sway election https://t.co/EZhgUIUbYx #'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use one tweet as an example\n",
    "tweet_eg = tweet_df['tweet_body'][8]\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and Pre-Processing The Texts\n",
    "We are interested in the text of the tweets.\n",
    "The unique thing about text analytics is there is no standard way of pre-processing the data. Depending on the problem you are trying to solve, the pre-processing can be different.\n",
    "In most cases, it consist of the following components:\n",
    "- Removing Unwanted Characters\n",
    "- Removing Punctuations\n",
    "- Removing Numbers\n",
    "- Standardizing Cases\n",
    "- Removing Stopwords\n",
    "We will explain each of them in our session.\n",
    "We will be using a package called NLTK (Natural Language Toolkit), and a package called re (Regular Expression) extensively in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Text Cleaning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular Expression itself is a very useful skill to learn.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A lot of the tweets contains reference urls, we want to remove them first\n",
    "def remove_url(text):\n",
    "\ttext = re.sub('http://[^ ]*', '', text)\n",
    "\ttext = re.sub('https://[^ ]*', '', text)\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'RT @MeetThePress: Watch our interview with @KellyannePolls: Russia \"did not succeed\" in attempts to sway election  #'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the function on our sample tweet\n",
    "tweet_eg = remove_url(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing the at users\n",
    "def remove_at_user(text):\n",
    "\timport re\n",
    "\treturn re.sub('@[^\\s]+','', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'RT  Watch our interview with  Russia \"did not succeed\" in attempts to sway election  #'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_eg = remove_at_user(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now try to write a function to remove the retweet 'RT'\n",
    "def remove_rt(text):\n",
    "    text = re.sub('RT', '', text, count=1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'  Watch our interview with  Russia \"did not succeed\" in attempts to sway election  #'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_eg = remove_rt(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's remove the punctuations and numbers, basically all the non letters for now\n",
    "def remove_non_letters(text):\n",
    "\treturn re.sub(\"[^a-zA-Z]\", \" \", text) \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'  Watch our interview with  Russia  did not succeed  in attempts to sway election   '"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_eg = remove_non_letters(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We might want to remove some extra blanks\n",
    "def remove_extra_blanks(text):\n",
    "\ttext = re.sub('\\n', ' ', text)\n",
    "\ttext = re.sub(\" +\",\" \",text).strip() #remove extra spaces\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Watch our interview with Russia did not succeed in attempts to sway election'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_eg = remove_extra_blanks(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'watch our interview with russia did not succeed in attempts to sway election'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing Cases\n",
    "def all_lower_case(text):\n",
    "\treturn text.lower()\n",
    "\n",
    "tweet_eg = all_lower_case(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let's put all of the above cleaning functions together\n",
    "def my_text_cleanser(text):\n",
    "    if isinstance(text,basestring):\n",
    "        text = text.encode('utf-8')\n",
    "        text = remove_url(text)\n",
    "        text = remove_rt(text)\n",
    "        text = remove_non_letters(text)\n",
    "        text = remove_extra_blanks(text)\n",
    "        text = all_lower_case(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will apply the text cleanser to our 'tweet_body' column, using a very commonly used function in pandas 'apply'\n",
    "tweet_df['tweet_body_clean'] = tweet_df.tweet_body.apply(my_text_cleanser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>tweet_body_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>RT @TheBriefing2016: Ted Cruz once called Donald Trump a pathological liar. And yet...here he is. #RNCinCLE https://t.co/ZfTFm1qy5Q</td>\n",
       "      <td>thebriefing ted cruz once called donald trump a pathological liar and yet here he is rncincle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>CNN anchors are completely out of touch with everyday people worried about rising crime, failing schools and vanishing jobs.</td>\n",
       "      <td>cnn anchors are completely out of touch with everyday people worried about rising crime failing schools and vanishing jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>A Wall Street money manager should not be able to pay a lower tax rate than a teacher or a nurse.</td>\n",
       "      <td>a wall street money manager should not be able to pay a lower tax rate than a teacher or a nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>To Donald, women like Alicia are only as valuable as his personal opinion about their looks. https://t.co/OZv8yg8vjZ https://t.co/PZWmPcORBR</td>\n",
       "      <td>to donald women like alicia are only as valuable as his personal opinion about their looks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>This election is over in 20 daysbut the decision we make will affect our country for generations.  #DebateNight https://t.co/SfQM2FdOAr</td>\n",
       "      <td>this election is over in daysbut the decision we make will affect our country for generations debatenight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        tweet_body  \\\n",
       "6428  RT @TheBriefing2016: Ted Cruz once called Donald Trump a pathological liar. And yet...here he is. #RNCinCLE https://t.co/ZfTFm1qy5Q            \n",
       "1503  CNN anchors are completely out of touch with everyday people worried about rising crime, failing schools and vanishing jobs.                   \n",
       "4496  A Wall Street money manager should not be able to pay a lower tax rate than a teacher or a nurse.                                              \n",
       "4591  To Donald, women like Alicia are only as valuable as his personal opinion about their looks. https://t.co/OZv8yg8vjZ https://t.co/PZWmPcORBR   \n",
       "3983  This election is over in 20 daysbut the decision we make will affect our country for generations.  #DebateNight https://t.co/SfQM2FdOAr        \n",
       "\n",
       "                                                                                                                tweet_body_clean  \n",
       "6428  thebriefing ted cruz once called donald trump a pathological liar and yet here he is rncincle                               \n",
       "1503  cnn anchors are completely out of touch with everyday people worried about rising crime failing schools and vanishing jobs  \n",
       "4496  a wall street money manager should not be able to pay a lower tax rate than a teacher or a nurse                            \n",
       "4591  to donald women like alicia are only as valuable as his personal opinion about their looks                                  \n",
       "3983  this election is over in daysbut the decision we make will affect our country for generations debatenight                   "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the old column and the cleaned new column\n",
    "tweet_df[['tweet_body','tweet_body_clean']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stopwords\n",
    "Stopwords are words that occur in a sentence often that do not carry any meanings, for example, 'am','and','the'.\n",
    "We often want to remove these words when we are doing text analytics.\n",
    "To do this, we will use NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't done so already, download the nltk's corpus for stopwords\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# Import the stop word list\n",
    "from nltk.corpus import stopwords \n",
    "print (stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    meaningful_words = [w for w in words if not w in stopwords.words(\"english\") ]\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'watch',\n",
       " u'interview',\n",
       " u'russia',\n",
       " u'succeed',\n",
       " u'attempts',\n",
       " u'sway',\n",
       " u'election']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_eg = remove_stopwords(tweet_eg)\n",
    "tweet_eg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Stemming\n",
    "In linguistic morphology and information retrieval, stemming is the process for reducing inflected (or sometimes derived) words to their stem, base or root form—generally a written word form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interact\n",
      "interact\n",
      "interact\n",
      "interact\n"
     ]
    }
   ],
   "source": [
    "# Examples of stemmed words\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "print (snowball_stemmer.stem('interaction'))\n",
    "print (snowball_stemmer.stem('interact'))\n",
    "print (snowball_stemmer.stem('interactions'))\n",
    "print (snowball_stemmer.stem('interactivity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Lemmatization\n",
    "Lemmatisation (or lemmatization) in linguistics, is the process of grouping together the different inflected forms of a word so they can be analysed as a single item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction\n",
      "interact\n",
      "interaction\n",
      "interactivity\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "print (wordnet_lemmatizer.lemmatize('interaction'))\n",
    "print (wordnet_lemmatizer.lemmatize('interact'))\n",
    "print (wordnet_lemmatizer.lemmatize('interactions'))\n",
    "print (wordnet_lemmatizer.lemmatize('interactivity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will be using the lemmatizer for our purpose\n",
    "def lemmatizer(words):\n",
    "    return [wordnet_lemmatizer.lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_text_tokenizer(text):\n",
    "    words = remove_stopwords(text)\n",
    "    words = lemmatizer(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's apply the functions above to our cleaned tweet\n",
    "tweet_df['tweet_body_terms'] = tweet_df.tweet_body_clean.apply(my_text_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>tweet_body_clean</th>\n",
       "      <th>tweet_body_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>RT @dougmillsnyt: .@HillaryClinton with JAY Z and Beyonce in Cleveland at the concert https://t.co/e8e8eofTsq</td>\n",
       "      <td>dougmillsnyt hillaryclinton with jay z and beyonce in cleveland at the concert</td>\n",
       "      <td>[dougmillsnyt, hillaryclinton, jay, z, beyonce, cleveland, concert]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>It doesn't matter that Crooked Hillary has experience, look at all of the bad decisions she has made. Bernie said she has bad judgement!</td>\n",
       "      <td>it doesn t matter that crooked hillary has experience look at all of the bad decisions she has made bernie said she has bad judgement</td>\n",
       "      <td>[matter, crooked, hillary, experience, look, bad, decision, made, bernie, said, bad, judgement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Great crowd in Johnstown, Pennsylvania- thank you. Get out &amp;amp; VOTE on 11/8! Watch the MOVEMENT in PA. this afternoon https://t.co/DUMlbSkVeY</td>\n",
       "      <td>great crowd in johnstown pennsylvania thank you get out amp vote on watch the movement in pa this afternoon</td>\n",
       "      <td>[great, crowd, johnstown, pennsylvania, thank, get, amp, vote, watch, movement, pa, afternoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>You should give the money back @HillaryClinton! #DrainTheSwamp https://t.co/m0LKHRUoHz</td>\n",
       "      <td>you should give the money back hillaryclinton draintheswamp</td>\n",
       "      <td>[give, money, back, hillaryclinton, draintheswamp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>Happy #WomensEqualityDay from @realDonaldTrump. https://t.co/YfUdtygL4h</td>\n",
       "      <td>happy womensequalityday from realdonaldtrump</td>\n",
       "      <td>[happy, womensequalityday, realdonaldtrump]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           tweet_body  \\\n",
       "3443  RT @dougmillsnyt: .@HillaryClinton with JAY Z and Beyonce in Cleveland at the concert https://t.co/e8e8eofTsq                                     \n",
       "1729  It doesn't matter that Crooked Hillary has experience, look at all of the bad decisions she has made. Bernie said she has bad judgement!          \n",
       "534   Great crowd in Johnstown, Pennsylvania- thank you. Get out &amp; VOTE on 11/8! Watch the MOVEMENT in PA. this afternoon https://t.co/DUMlbSkVeY   \n",
       "581   You should give the money back @HillaryClinton! #DrainTheSwamp https://t.co/m0LKHRUoHz                                                            \n",
       "5407  Happy #WomensEqualityDay from @realDonaldTrump. https://t.co/YfUdtygL4h                                                                           \n",
       "\n",
       "                                                                                                                           tweet_body_clean  \\\n",
       "3443  dougmillsnyt hillaryclinton with jay z and beyonce in cleveland at the concert                                                          \n",
       "1729  it doesn t matter that crooked hillary has experience look at all of the bad decisions she has made bernie said she has bad judgement   \n",
       "534   great crowd in johnstown pennsylvania thank you get out amp vote on watch the movement in pa this afternoon                             \n",
       "581   you should give the money back hillaryclinton draintheswamp                                                                             \n",
       "5407  happy womensequalityday from realdonaldtrump                                                                                            \n",
       "\n",
       "                                                                                     tweet_body_terms  \n",
       "3443  [dougmillsnyt, hillaryclinton, jay, z, beyonce, cleveland, concert]                              \n",
       "1729  [matter, crooked, hillary, experience, look, bad, decision, made, bernie, said, bad, judgement]  \n",
       "534   [great, crowd, johnstown, pennsylvania, thank, get, amp, vote, watch, movement, pa, afternoon]   \n",
       "581   [give, money, back, hillaryclinton, draintheswamp]                                               \n",
       "5407  [happy, womensequalityday, realdonaldtrump]                                                      "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at what we've done so far\n",
    "tweet_df[['tweet_body','tweet_body_clean','tweet_body_terms']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Text Analytics on Tweets\n",
    "With the text pre-processed, we can now do some simple but interesting analytics on the tweets, in this session, we will look at for Trump and Hilary \n",
    "- Term Collocation\n",
    "- Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we will be creating statistics at user level, we group the dataframe by users\n",
    "users_df = tweet_df.groupby('handle').agg({'tweet_body_terms':sum,'tweet_body_clean':lambda x: ' '.join(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Collocations\n",
    "Collocations are partly or fully fixed expressions that become established through repeated context-dependent use. \n",
    "For example, 'crystal clear', 'middle management', and 'plastic surgery' are examples of collocated pairs of words.\n",
    "We are interested in looking at term collocations the context gives us a better insight about the meaning of a term, supporting applications such as word disambiguation or semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find top collocation in the tweets\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "def top_collocation_text(words):\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(words)\n",
    "    finder.apply_freq_filter(5)\n",
    "    return finder.nbest(bigram_measures.pmi, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see what are the most often talked about terms for Hilary and Trump\n",
    "users_df['top_collocation_text'] = users_df.tweet_body_terms.apply(top_collocation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle\n",
      "HillaryClinton     [(anywhere, near), (bin, laden), (jay, z), (klux, klan), (ku, klux), (role, model), (hiv, aid), (hurricane, matthew), (pm, et), (conspiracy, theory), (glass, ceiling), (north, carolina), (zip, code), (editorial, board), (common, ground), (energy, superpower), (birther, movement), (comprehensive, immigration), (locker, room), (humayun, khan)]              \n",
      "realDonaldTrump    [(rolling, thunder), (electoral, college), (sometimes, referred), (rhode, island), (supreme, court), (mobile, alabama), (san, diego), (san, jose), (bobby, knight), (referred, pocahontas), (coach, bobby), (lindsey, graham), (self, funding), (paul, ryan), (town, hall), (grand, rapid), (conflict, interest), (facebook, page), (mitt, romney), (radical, islam)]\n",
      "Name: top_collocation_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (users_df['top_collocation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical Diversity\n",
    "Lexical diversity is a measure of how many different words that are used in a text.\n",
    "The more varied a vocabulary a text possesses, the higher lexical diversity.\n",
    "For a text to be highly lexically diverse, the speaker or writer has to use many\n",
    "different words, with littie repetition of the words already used. \n",
    "The lexical diversity of a given text is defined as the ratio of total number of words to the number of different unique word stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(words):\n",
    "    return 1.0*len(set(words))/(len(words)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_df['lexical_diversity'] = users_df.tweet_body_terms.apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle\n",
      "HillaryClinton     0.166746\n",
      "realDonaldTrump    0.162534\n",
      "Name: lexical_diversity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (users_df['lexical_diversity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
